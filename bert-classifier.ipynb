{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceType":"datasetVersion","sourceId":442620,"datasetId":200769,"databundleVersionId":458250},{"sourceType":"modelInstanceVersion","sourceId":6068,"databundleVersionId":7429247,"modelInstanceId":4689}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn import feature_extraction, linear_model, model_selection, preprocessing\nimport tensorflow as tf\n#import keras_core as keras\nimport keras_nlp\nfrom sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nimport os\nos.environ[\"KERAS_BACKEND\"] = \"tensorflow\" \n\nimport keras\nimport keras_nlp\n\nimport tensorflow as tf\n\nimport json\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\n\nimport plotly.graph_objs as go\nimport plotly.express as px","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-16T22:09:38.500719Z","iopub.execute_input":"2024-05-16T22:09:38.501509Z","iopub.status.idle":"2024-05-16T22:09:54.098529Z","shell.execute_reply.started":"2024-05-16T22:09:38.501480Z","shell.execute_reply":"2024-05-16T22:09:54.097743Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"2024-05-16 22:09:42.229747: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-05-16 22:09:42.229831: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-05-16 22:09:42.358851: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"print(\"TensorFlow version:\", tf.__version__)\nprint(\"KerasNLP version:\", keras_nlp.__version__)","metadata":{"execution":{"iopub.status.busy":"2024-05-16T22:10:12.138092Z","iopub.execute_input":"2024-05-16T22:10:12.138789Z","iopub.status.idle":"2024-05-16T22:10:12.144122Z","shell.execute_reply.started":"2024-05-16T22:10:12.138759Z","shell.execute_reply":"2024-05-16T22:10:12.142961Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"TensorFlow version: 2.15.0\nKerasNLP version: 0.9.3\n","output_type":"stream"}]},{"cell_type":"code","source":"model_type=\"distil_bert_base_en_uncased\"","metadata":{"execution":{"iopub.status.busy":"2024-05-16T22:10:13.920789Z","iopub.execute_input":"2024-05-16T22:10:13.921457Z","iopub.status.idle":"2024-05-16T22:10:13.925521Z","shell.execute_reply.started":"2024-05-16T22:10:13.921426Z","shell.execute_reply":"2024-05-16T22:10:13.924432Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"reviews = pd.read_json('/kaggle/input/imdb-spoiler-dataset/IMDB_reviews.json', lines=True)\ndef replace_string_binary(x):\n    if x:\n        return 1\n    return 0\n\nreviews['is_spoiler'] = reviews['is_spoiler'].apply(lambda x: replace_string_binary(x))\nreviews","metadata":{"execution":{"iopub.status.busy":"2024-05-16T22:10:16.685421Z","iopub.execute_input":"2024-05-16T22:10:16.685803Z","iopub.status.idle":"2024-05-16T22:10:37.773944Z","shell.execute_reply.started":"2024-05-16T22:10:16.685774Z","shell.execute_reply":"2024-05-16T22:10:37.772888Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"             review_date   movie_id    user_id  is_spoiler  \\\n0       10 February 2006  tt0111161  ur1898687           1   \n1       6 September 2000  tt0111161  ur0842118           1   \n2          3 August 2001  tt0111161  ur1285640           1   \n3       1 September 2002  tt0111161  ur1003471           1   \n4            20 May 2004  tt0111161  ur0226855           1   \n...                  ...        ...        ...         ...   \n573908     8 August 1999  tt0139239  ur0100166           0   \n573909      31 July 1999  tt0139239  ur0021767           0   \n573910      20 July 1999  tt0139239  ur0392750           0   \n573911      11 June 1999  tt0139239  ur0349105           0   \n573912        3 May 1999  tt0139239  ur0156431           0   \n\n                                              review_text  rating  \\\n0       In its Oscar year, Shawshank Redemption (writt...      10   \n1       The Shawshank Redemption is without a doubt on...      10   \n2       I believe that this film is the best story eve...       8   \n3       **Yes, there are SPOILERS here**This film has ...      10   \n4       At the heart of this extraordinary movie is a ...       8   \n...                                                   ...     ...   \n573908  Go is wise, fast and pure entertainment. Assem...      10   \n573909  Well, what shall I say. this one´s fun at any ...       9   \n573910  Go is the best movie I have ever seen, and I'v...      10   \n573911  Call this 1999 teenage version of Pulp Fiction...       3   \n573912  Why was this movie made? No doubt to sucker in...       2   \n\n                                       review_summary  \n0       A classic piece of unforgettable film-making.  \n1          Simply amazing. The best film of the 90's.  \n2                    The best story ever told on film  \n3                          Busy dying or busy living?  \n4              Great story, wondrously told and acted  \n...                                               ...  \n573908            The best teen movie of the nineties  \n573909                             Go - see the movie  \n573910             It's the best movie I've ever seen  \n573911                   Haven't we seen this before?  \n573912                         Go doesn't go anywhere  \n\n[573913 rows x 7 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review_date</th>\n      <th>movie_id</th>\n      <th>user_id</th>\n      <th>is_spoiler</th>\n      <th>review_text</th>\n      <th>rating</th>\n      <th>review_summary</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>10 February 2006</td>\n      <td>tt0111161</td>\n      <td>ur1898687</td>\n      <td>1</td>\n      <td>In its Oscar year, Shawshank Redemption (writt...</td>\n      <td>10</td>\n      <td>A classic piece of unforgettable film-making.</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>6 September 2000</td>\n      <td>tt0111161</td>\n      <td>ur0842118</td>\n      <td>1</td>\n      <td>The Shawshank Redemption is without a doubt on...</td>\n      <td>10</td>\n      <td>Simply amazing. The best film of the 90's.</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3 August 2001</td>\n      <td>tt0111161</td>\n      <td>ur1285640</td>\n      <td>1</td>\n      <td>I believe that this film is the best story eve...</td>\n      <td>8</td>\n      <td>The best story ever told on film</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1 September 2002</td>\n      <td>tt0111161</td>\n      <td>ur1003471</td>\n      <td>1</td>\n      <td>**Yes, there are SPOILERS here**This film has ...</td>\n      <td>10</td>\n      <td>Busy dying or busy living?</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>20 May 2004</td>\n      <td>tt0111161</td>\n      <td>ur0226855</td>\n      <td>1</td>\n      <td>At the heart of this extraordinary movie is a ...</td>\n      <td>8</td>\n      <td>Great story, wondrously told and acted</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>573908</th>\n      <td>8 August 1999</td>\n      <td>tt0139239</td>\n      <td>ur0100166</td>\n      <td>0</td>\n      <td>Go is wise, fast and pure entertainment. Assem...</td>\n      <td>10</td>\n      <td>The best teen movie of the nineties</td>\n    </tr>\n    <tr>\n      <th>573909</th>\n      <td>31 July 1999</td>\n      <td>tt0139239</td>\n      <td>ur0021767</td>\n      <td>0</td>\n      <td>Well, what shall I say. this one´s fun at any ...</td>\n      <td>9</td>\n      <td>Go - see the movie</td>\n    </tr>\n    <tr>\n      <th>573910</th>\n      <td>20 July 1999</td>\n      <td>tt0139239</td>\n      <td>ur0392750</td>\n      <td>0</td>\n      <td>Go is the best movie I have ever seen, and I'v...</td>\n      <td>10</td>\n      <td>It's the best movie I've ever seen</td>\n    </tr>\n    <tr>\n      <th>573911</th>\n      <td>11 June 1999</td>\n      <td>tt0139239</td>\n      <td>ur0349105</td>\n      <td>0</td>\n      <td>Call this 1999 teenage version of Pulp Fiction...</td>\n      <td>3</td>\n      <td>Haven't we seen this before?</td>\n    </tr>\n    <tr>\n      <th>573912</th>\n      <td>3 May 1999</td>\n      <td>tt0139239</td>\n      <td>ur0156431</td>\n      <td>0</td>\n      <td>Why was this movie made? No doubt to sucker in...</td>\n      <td>2</td>\n      <td>Go doesn't go anywhere</td>\n    </tr>\n  </tbody>\n</table>\n<p>573913 rows × 7 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Split data into training and test sets (80% train, 20% test)\ntrain_data, test_data = train_test_split(reviews, test_size=0.1, random_state=42)\n\n# Define a function to parse the DataFrame\ndef parse_dataframe(df):\n    # Return features (text review) and labels (sentiment label)\n    return df[\"review_text\"].values, df[\"is_spoiler\"].values\n\n# Convert training and test data to TensorFlow datasets\ntrain_dataset = tf.data.Dataset.from_tensor_slices(parse_dataframe(train_data)).batch(32)\ntest_dataset = tf.data.Dataset.from_tensor_slices(parse_dataframe(test_data)).batch(32)","metadata":{"execution":{"iopub.status.busy":"2024-05-16T22:10:52.664570Z","iopub.execute_input":"2024-05-16T22:10:52.665481Z","iopub.status.idle":"2024-05-16T22:10:53.823054Z","shell.execute_reply.started":"2024-05-16T22:10:52.665450Z","shell.execute_reply":"2024-05-16T22:10:53.822039Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"tokenizer = keras_nlp.models.DistilBertTokenizer.from_preset(model_type)\nbackbone = keras_nlp.models.DistilBertBackbone.from_preset(model_type)","metadata":{"execution":{"iopub.status.busy":"2024-05-16T22:10:56.653351Z","iopub.execute_input":"2024-05-16T22:10:56.653684Z","iopub.status.idle":"2024-05-16T22:11:05.948669Z","shell.execute_reply.started":"2024-05-16T22:10:56.653658Z","shell.execute_reply":"2024-05-16T22:11:05.947599Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"Attaching 'tokenizer.json' from model 'keras/distil_bert/keras/distil_bert_base_en_uncased/2' to your Kaggle notebook...\nAttaching 'tokenizer.json' from model 'keras/distil_bert/keras/distil_bert_base_en_uncased/2' to your Kaggle notebook...\nAttaching 'assets/tokenizer/vocabulary.txt' from model 'keras/distil_bert/keras/distil_bert_base_en_uncased/2' to your Kaggle notebook...\nAttaching 'config.json' from model 'keras/distil_bert/keras/distil_bert_base_en_uncased/2' to your Kaggle notebook...\nAttaching 'config.json' from model 'keras/distil_bert/keras/distil_bert_base_en_uncased/2' to your Kaggle notebook...\nAttaching 'model.weights.h5' from model 'keras/distil_bert/keras/distil_bert_base_en_uncased/2' to your Kaggle notebook...\n","output_type":"stream"}]},{"cell_type":"code","source":"packer = keras_nlp.layers.MultiSegmentPacker(\n    start_value=tokenizer.cls_token_id,\n    end_value=tokenizer.sep_token_id,\n    pad_value=tokenizer.pad_token_id,\n    sequence_length=500\n)\n\ndef preprocess(x, y):\n    token_ids, _ = packer(tokenizer(x))\n    x = {\n        \"token_ids\": token_ids,\n        \"padding_mask\": token_ids != tokenizer.pad_token_id,\n    }\n    return x, y\n\ntrain_ds = train_dataset.map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)\nval_ds = test_dataset.map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)","metadata":{"execution":{"iopub.status.busy":"2024-05-16T22:11:14.556363Z","iopub.execute_input":"2024-05-16T22:11:14.556750Z","iopub.status.idle":"2024-05-16T22:11:16.144502Z","shell.execute_reply.started":"2024-05-16T22:11:14.556717Z","shell.execute_reply":"2024-05-16T22:11:16.143653Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras import callbacks\n\nearly_stopping = callbacks.EarlyStopping(\n    min_delta=0.001, # minimium amount of change to count as an improvement\n    patience=3, # how many epochs to wait before stopping\n    restore_best_weights=True,\n)\n\ncheckpoint = keras.callbacks.ModelCheckpoint(\n    \"./spoiler.keras\",\n    monitor='val_accuracy',\n    verbose=0,\n    save_best_only=True,\n    mode='auto'\n)\n\nrlr = keras.callbacks.ReduceLROnPlateau(\n        monitor='val_accuracy', \n        factor=1/3, \n        patience=3, \n        min_lr=1e-6\n)\n\ncallbacks = [early_stopping, checkpoint, rlr]","metadata":{"execution":{"iopub.status.busy":"2024-05-16T22:11:20.391871Z","iopub.execute_input":"2024-05-16T22:11:20.392241Z","iopub.status.idle":"2024-05-16T22:11:20.398327Z","shell.execute_reply.started":"2024-05-16T22:11:20.392211Z","shell.execute_reply":"2024-05-16T22:11:20.397362Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"inputs = backbone.input\noutputs = backbone(inputs)[:, 0, :]\n#outputs = keras.layers.Dense(2028,activation='relu')(outputs)\noutputs = keras.layers.Dense(1024,activation='relu')(outputs)\noutputs = keras.layers.Dense(512,activation='relu')(outputs)\noutputs = keras.layers.Dense(256, activation='relu')(outputs)\noutputs = keras.layers.Dense(128,activation='relu')(outputs)\n\noutputs = keras.layers.Dropout(0.1)(outputs)\n\noutputs = keras.layers.Dense(2)(outputs)\n    \nmodel = keras.Model(inputs, outputs)\nmodel.compile(\n    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n    optimizer=keras.optimizers.Adam(1e-5),\n     metrics= [\"accuracy\"],\n    jit_compile=True,\n    \n)\n\nhistory=model.fit(\n    train_ds, \n    validation_data=val_ds,\n    epochs=2, \n    callbacks=callbacks\n)","metadata":{"execution":{"iopub.status.busy":"2024-05-16T22:11:25.540088Z","iopub.execute_input":"2024-05-16T22:11:25.540569Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Epoch 1/2\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1715897543.567237     116 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\nW0000 00:00:1715897543.613625     116 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m  786/16142\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:07:00\u001b[0m 731ms/step - accuracy: 0.7469 - loss: 0.5255","output_type":"stream"}]},{"cell_type":"markdown","source":"## HuggingFace Transformers","metadata":{}},{"cell_type":"code","source":"!pip install peft","metadata":{"execution":{"iopub.status.busy":"2024-05-16T22:29:34.816690Z","iopub.execute_input":"2024-05-16T22:29:34.817323Z","iopub.status.idle":"2024-05-16T22:29:48.377181Z","shell.execute_reply.started":"2024-05-16T22:29:34.817290Z","shell.execute_reply":"2024-05-16T22:29:48.376224Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting peft\n  Downloading peft-0.11.0-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from peft) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from peft) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from peft) (6.0.1)\nRequirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from peft) (2.1.2)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from peft) (4.39.3)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from peft) (4.66.1)\nRequirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from peft) (0.29.3)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from peft) (0.4.3)\nRequirement already satisfied: huggingface-hub>=0.17.0 in /opt/conda/lib/python3.10/site-packages (from peft) (0.22.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (3.13.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2024.2.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2.31.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->peft) (3.1.1)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (2023.12.25)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (0.15.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (2024.2.2)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\nDownloading peft-0.11.0-py3-none-any.whl (251 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m251.2/251.2 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: peft\nSuccessfully installed peft-0.11.0\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import AutoTokenizer, DataCollatorWithPadding\nimport pandas as pd\n\nreviews = pd.read_json('/kaggle/input/imdb-spoiler-dataset/IMDB_reviews.json', lines=True)\ndef replace_string_binary(x):\n    if x:\n        return 1\n    return 0\n\nreviews['label'] = reviews['is_spoiler'].apply(lambda x: replace_string_binary(x))\ndf = reviews[['review_text', 'label']]\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-16T22:53:42.262240Z","iopub.execute_input":"2024-05-16T22:53:42.262564Z","iopub.status.idle":"2024-05-16T22:53:52.501024Z","shell.execute_reply.started":"2024-05-16T22:53:42.262538Z","shell.execute_reply":"2024-05-16T22:53:52.499948Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"                                         review_text  label\n0  In its Oscar year, Shawshank Redemption (writt...      1\n1  The Shawshank Redemption is without a doubt on...      1\n2  I believe that this film is the best story eve...      1\n3  **Yes, there are SPOILERS here**This film has ...      1\n4  At the heart of this extraordinary movie is a ...      1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review_text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>In its Oscar year, Shawshank Redemption (writt...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>The Shawshank Redemption is without a doubt on...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>I believe that this film is the best story eve...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>**Yes, there are SPOILERS here**This film has ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>At the heart of this extraordinary movie is a ...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"from datasets import Dataset\n\nhf_dataset = Dataset.from_pandas(df)\nhf_dataset","metadata":{"execution":{"iopub.status.busy":"2024-05-16T22:54:01.527790Z","iopub.execute_input":"2024-05-16T22:54:01.528503Z","iopub.status.idle":"2024-05-16T22:54:07.991471Z","shell.execute_reply.started":"2024-05-16T22:54:01.528471Z","shell.execute_reply":"2024-05-16T22:54:07.990553Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['review_text', 'label'],\n    num_rows: 573913\n})"},"metadata":{}}]},{"cell_type":"code","source":"checkpoint = \"google-bert/bert-base-cased\"\ntokenizer = AutoTokenizer.from_pretrained(checkpoint)\n\ndef tokenize_fn(examples):\n    return tokenizer(examples['review_text'], truncation=True)\n\ntokenized_datasets = hf_dataset.map(tokenize_fn, batched=True)\ndata_collator = DataCollatorWithPadding(tokenizer)","metadata":{"execution":{"iopub.status.busy":"2024-05-16T22:55:52.227261Z","iopub.execute_input":"2024-05-16T22:55:52.227628Z","iopub.status.idle":"2024-05-16T23:01:22.138830Z","shell.execute_reply.started":"2024-05-16T22:55:52.227595Z","shell.execute_reply":"2024-05-16T23:01:22.137877Z"},"trusted":true},"execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/573913 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"14b1358e1c014bb998f2ae1aeee5ea14"}},"metadata":{}}]},{"cell_type":"code","source":"tokenized_datasets","metadata":{"execution":{"iopub.status.busy":"2024-05-16T23:01:42.047538Z","iopub.execute_input":"2024-05-16T23:01:42.048248Z","iopub.status.idle":"2024-05-16T23:01:42.054565Z","shell.execute_reply.started":"2024-05-16T23:01:42.048209Z","shell.execute_reply":"2024-05-16T23:01:42.053488Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['review_text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n    num_rows: 573913\n})"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import AutoModelForSequenceClassification\nfrom peft import get_peft_model, LoraConfig, TaskType\nmodel = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)\npeft_config = LoraConfig(\n    task_type=TaskType.SEQ_CLS,\n    inference_mode=False,\n    r=8,\n    lora_alpha=32,\n    lora_dropout=0.1\n)\nmodel = get_peft_model(model, peft_config)\nmodel.print_trainable_parameters()","metadata":{"execution":{"iopub.status.busy":"2024-05-16T23:02:51.017358Z","iopub.execute_input":"2024-05-16T23:02:51.017786Z","iopub.status.idle":"2024-05-16T23:02:51.615094Z","shell.execute_reply.started":"2024-05-16T23:02:51.017744Z","shell.execute_reply":"2024-05-16T23:02:51.614013Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"trainable params: 296,450 || all params: 108,608,260 || trainable%: 0.2730\n","output_type":"stream"}]},{"cell_type":"code","source":"split_datasets = tokenized_datasets.train_test_split(test_size=0.2)","metadata":{"execution":{"iopub.status.busy":"2024-05-16T23:03:12.808912Z","iopub.execute_input":"2024-05-16T23:03:12.809247Z","iopub.status.idle":"2024-05-16T23:03:13.053806Z","shell.execute_reply.started":"2024-05-16T23:03:12.809222Z","shell.execute_reply":"2024-05-16T23:03:13.053054Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"from transformers import TrainingArguments\n\ntraining_args = TrainingArguments(\n    \"test-trainer\",\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=16,\n    num_train_epochs=2,\n    learning_rate=1e-5,\n    weight_decay=0.01\n)","metadata":{"execution":{"iopub.status.busy":"2024-05-16T23:05:40.371926Z","iopub.execute_input":"2024-05-16T23:05:40.372287Z","iopub.status.idle":"2024-05-16T23:05:40.446878Z","shell.execute_reply.started":"2024-05-16T23:05:40.372258Z","shell.execute_reply":"2024-05-16T23:05:40.446054Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"from transformers import Trainer\n\ntrainer = Trainer(\n    model,\n    training_args,\n    train_dataset=split_datasets[\"train\"],\n    eval_dataset=split_datasets[\"test\"],\n    data_collator=data_collator,\n    tokenizer=tokenizer\n)\n\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-05-16T23:07:41.607325Z","iopub.execute_input":"2024-05-16T23:07:41.608181Z","iopub.status.idle":"2024-05-16T23:12:14.325930Z","shell.execute_reply.started":"2024-05-16T23:07:41.608140Z","shell.execute_reply":"2024-05-16T23:12:14.324741Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \ndataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n  warnings.warn(\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240516_230814-i4l3i2tu</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/ilyas-17/huggingface/runs/i4l3i2tu' target=\"_blank\">decent-haze-4</a></strong> to <a href='https://wandb.ai/ilyas-17/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/ilyas-17/huggingface' target=\"_blank\">https://wandb.ai/ilyas-17/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/ilyas-17/huggingface/runs/i4l3i2tu' target=\"_blank\">https://wandb.ai/ilyas-17/huggingface/runs/i4l3i2tu</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='342' max='57392' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [  342/57392 03:38 < 10:10:03, 1.56 it/s, Epoch 0.01/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"\nKeyboardInterrupt\n\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}